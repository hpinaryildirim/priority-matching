{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGSUCqEWgnfo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n",
        "from typing import List, Tuple\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "!pip install pulp\n",
        "from pulp import *\n",
        "import datetime\n",
        "import os\n",
        "import ast\n",
        "from scipy.spatial import distance\n",
        "import random\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import FormatStrFormatter\n",
        "import psutil\n",
        "import platform\n",
        "import shutil\n",
        "import subprocess\n",
        "import importlib\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkFjGBEigw27"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vyiaoqlPrUN"
      },
      "outputs": [],
      "source": [
        "def get_gpu_info():\n",
        "    try:\n",
        "        gpu_info = subprocess.check_output(\n",
        "            \"nvidia-smi --query-gpu=name,memory.total --format=csv,noheader\",\n",
        "            shell=True\n",
        "        )\n",
        "        return gpu_info.decode(\"utf-8\").strip()\n",
        "    except:\n",
        "        return \"No GPU detected\"\n",
        "\n",
        "def get_package_version(pkg_name):\n",
        "    try:\n",
        "        return importlib.import_module(pkg_name).__version__\n",
        "    except:\n",
        "        return \"Not installed\"\n",
        "\n",
        "def system_report():\n",
        "    print(\"=== Google Colab Runtime Specs ===\")\n",
        "    print(f\"Python version: {platform.python_version()}\")\n",
        "    print(f\"CPU cores (vCPUs): {psutil.cpu_count(logical=True)}\")\n",
        "    print(f\"Total RAM: {round(psutil.virtual_memory().total / (1024**3), 2)} GB\")\n",
        "    print(f\"Disk capacity: {round(shutil.disk_usage('/').total / (1024**3), 2)} GB\")\n",
        "    print(f\"GPU: {get_gpu_info()}\")\n",
        "    print(\"\\n=== Key Libraries ===\")\n",
        "    for pkg in [\"numpy\", \"pandas\", \"scipy\", \"pulp\"]:\n",
        "        print(f\"{pkg}: {get_package_version(pkg)}\")\n",
        "    print(\"==================================\")\n",
        "\n",
        "system_report()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnAFWTEihJ4u"
      },
      "source": [
        "## **Generate experiment data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RABubDJOhSo-"
      },
      "outputs": [],
      "source": [
        "def generate_spatial_experimental(size: int, scale: float = 2000) -> List[Tuple[float, float]]:\n",
        "    \"\"\"Generate arrival locations that are distributed according to the analysis of NYC taxi rides data.\n",
        "\n",
        "    Args\n",
        "    size: Number of locations to be generated.\n",
        "    scale: Avg meters away from the center.\n",
        "    \"\"\"\n",
        "    locx_list = []\n",
        "    locy_list = []\n",
        "\n",
        "    dist_x = np.random.exponential(scale, size)\n",
        "    signs_x = np.where(np.random.rand(size) > 0.5, 1, -1)\n",
        "    locx = dist_x * signs_x\n",
        "    locx = np.round(locx, 3).astype(float)\n",
        "    \"\"\"for d in dist_x:\n",
        "      locx_list.append(d if float(np.random.rand()) > 0.5 else -d)\n",
        "      locx_list = list(np.around(np.array(locx_list), 3))\"\"\"\n",
        "\n",
        "    dist_y = np.random.exponential(scale, size)\n",
        "    signs_y = np.where(np.random.rand(size) > 0.5, 1, -1)\n",
        "    locy = dist_y * signs_y\n",
        "    locy = np.round(locy, 3).astype(float)\n",
        "    \"\"\"for d in dist_y:\n",
        "      locy_list.append(d if float(np.random.rand()) > 0.5 else -d)\n",
        "      locy_list = list(np.around(np.array(locy_list), 3))\"\"\"\n",
        "\n",
        "    coords = [(float(x), float(y)) for x, y in zip(locx, locy)]\n",
        "    return coords\n",
        "\n",
        "\n",
        "def generate_priority_df(size: int, priority_probs: List[float]) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Generate a DataFrame of binary priority flags for a set of entities.\n",
        "\n",
        "    Args:\n",
        "        size (int): Number of entities.\n",
        "        priority_probs (List[float]): List of priority probabilities.\n",
        "    \"\"\"\n",
        "    columns = []\n",
        "    data = []\n",
        "    for prob in priority_probs:\n",
        "        n_priority = round(prob * size)\n",
        "        prio = np.array([1] * n_priority + [0] * (size - n_priority))\n",
        "        np.random.shuffle(prio)\n",
        "        data.append(prio)\n",
        "        columns.append(f\"priority_{prob}\")\n",
        "\n",
        "    return pd.DataFrame(np.array(data).T, columns=columns)\n",
        "\n",
        "\n",
        "def generate_data(seed: int, size_set1: int, size_set2:int, priority_prob1_set: List[float], priority_prob2_set: List[float]) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "  \"\"\"Generate experiment data.\n",
        "\n",
        "  Args:\n",
        "    seed (int): Random seed for reproducibility.\n",
        "    size_set1 (int): Number of entities in set 1.\n",
        "    size_set2 (int): Number of entities in set 2.\n",
        "    priority_prob1_set (List[float]): Priority probabilities for set 1.\n",
        "    priority_prob2_set (List[float]): Priority probabilities for set 2.\n",
        "  \"\"\"\n",
        "  np.random.seed(seed)\n",
        "\n",
        "  loc_set1 = generate_spatial_experimental(size_set1)\n",
        "  loc_set2 = generate_spatial_experimental(size_set2)\n",
        "\n",
        "  set1_prio = generate_priority_df(size_set1, priority_prob1_set)\n",
        "  set2_prio = generate_priority_df(size_set2, priority_prob2_set)\n",
        "\n",
        "  set1_ids = [f\"p_{str(i).rjust(len(str(size_set1)), '0')}\" for i in range(size_set1)]\n",
        "  set2_ids = [f\"d_{str(i).rjust(len(str(size_set2)), '0')}\" for i in range(size_set2)]\n",
        "\n",
        "  set1_df = pd.DataFrame({'id': set1_ids, 'loc': loc_set1})\n",
        "  set1_df = pd.concat([set1_df, set1_prio], axis=1)\n",
        "\n",
        "  set2_df = pd.DataFrame({'id': set2_ids, 'loc': loc_set2})\n",
        "  set2_df = pd.concat([set2_df, set2_prio], axis=1)\n",
        "\n",
        "  return set1_df, set2_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bt2rscI36La"
      },
      "outputs": [],
      "source": [
        "data_save_loc = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Z4OD-pNhLan"
      },
      "outputs": [],
      "source": [
        "num_set1 = [50]\n",
        "prob_set1 = [0.05, 0.1, 0.2, 0.3]\n",
        "\n",
        "num_set2 = [12, 25, 37]\n",
        "prob_set2 = [0.05, 0.1, 0.2, 0.3]\n",
        "\n",
        "seeds = [290, 534, 839, 490, 445, 771, 726, 871, 883, 518, 895, 978, 295, 158, 85, 244, 723, 137, 361, 589, 716, 584, 925, 436, 285, 159, 456, 492, 149, 184, 888, 760, 46, 961, 964, 349, 117, 551,\n",
        "                     24, 174, 354, 342, 719, 198, 935, 452, 279, 809, 132, 171, 849, 109, 945, 30, 529, 724, 150, 940, 800, 714, 503, 249, 92, 463, 906, 562, 677, 844, 597, 608, 25, 55, 624, 563, 145, 851,\n",
        "                     518, 726, 625, 982, 85, 748, 27, 609, 218, 303, 31, 6, 91, 202, 291, 212, 661, 344, 866, 943, 360, 247, 209, 164]\n",
        "\n",
        "param_set_list = []\n",
        "\n",
        "for set_count, (n_of_p, n_of_d) in enumerate(itertools.product(num_set1, num_set2), start=1):\n",
        "\n",
        "        param_set =  f\"Parameter Setting {set_count}, {n_of_p},  {n_of_d}\"\n",
        "        param_set_list.append(param_set)\n",
        "        print(param_set)\n",
        "\n",
        "        for count, seed in enumerate(seeds, start=1):\n",
        "            df1, df2 = generate_data(seed=seed,\n",
        "                                      size_set1=n_of_p,\n",
        "                                      size_set2 = n_of_d,\n",
        "                                      priority_prob1_set=prob_set1,\n",
        "                                      priority_prob2_set=prob_set2)\n",
        "\n",
        "            os.makedirs(data_save_loc, exist_ok=True)\n",
        "            df1.to_csv(f\"{data_save_loc}/df1_{set_count:03d}_{count:03d}.csv\", index=False)\n",
        "            df2.to_csv(f\"{data_save_loc}/df2_{set_count:03d}_{count:03d}.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2k21ZtCl7Bi"
      },
      "source": [
        "## **Experiments**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uLtq2NSl_jP"
      },
      "outputs": [],
      "source": [
        "def min_cost_matching(distance_matrix: np.ndarray, distance_threshold: float, passenger_priority: List[int], driver_priority: List[int]) -> Tuple[pd.DataFrame, int, int, float]:\n",
        "    \"\"\" Computes the minimum cost matching between drivers and passengers using the Hungarian algorithm (linear_sum_assignment).\n",
        "\n",
        "    Args:\n",
        "      distance_matrix (np.ndarray: Distance matrix of shape [num_cars, num_passengers] representing distances between each driver and passenger.\n",
        "      distance_threshold (float): Maximum feasible distance for an assignment. Any distance above this threshold is considered infeasible.\n",
        "      passenger_priority (List[int]): List indicating priority status of each passenger. Priority value `2` is considered \"priority\". Priority value `1` is considered non-\"priority\".\n",
        "      driver_priority (List[int]): List indicating priority status of each driver. Priority value `2` is considered \"priority\". Priority value `1` is considered non-\"priority\".\n",
        "    \"\"\"\n",
        "    mat = np.array(distance_matrix, copy=True)\n",
        "\n",
        "    #Infeasible distances\n",
        "    mat[mat > distance_threshold] = 1e6\n",
        "\n",
        "    if np.any(mat < 1e6):\n",
        "       #Solve the linear sum assignment problem\n",
        "       driver_indices, passenger_indices  = linear_sum_assignment(mat, maximize=False)\n",
        "\n",
        "       #Extract the matches\n",
        "       assignment_distances = [mat[i][j]  for (i,j) in zip(driver_indices, passenger_indices)]\n",
        "       assignment_df = pd.DataFrame({\"car_ind\": driver_indices, \"pass_ind\": passenger_indices, \"dist\": assignment_distances})\n",
        "       assignment_df = assignment_df.loc[assignment_df[\"dist\"] <= distance_threshold]\n",
        "\n",
        "       #Calculate the total cost\n",
        "       total_cost = assignment_df[\"dist\"].sum()\n",
        "\n",
        "       matched_drivers = assignment_df[\"car_ind\"].nunique()\n",
        "       matched_passengers = assignment_df[\"pass_ind\"].nunique()\n",
        "\n",
        "       if matched_drivers != matched_passengers:\n",
        "          raise Exception(\"Unmatched assignment: number of matched cars and passengers differ.\")\n",
        "\n",
        "       num_matched_priority_passengers = assignment_df[\"pass_ind\"].apply(lambda j: passenger_priority[j] != 1).sum()\n",
        "       num_matched_priority_drivers = assignment_df[\"car_ind\"].apply(lambda i: driver_priority[i] != 1).sum()\n",
        "\n",
        "       return len(assignment_df), int(num_matched_priority_passengers), int(num_matched_priority_drivers), float(total_cost), None\n",
        "\n",
        "    else:\n",
        "      return 0, 0, 0, np.inf, 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIIgj6sngw8t"
      },
      "outputs": [],
      "source": [
        "def constrained_max_weight_matching(distance_matrix: np.ndarray, distance_threshold: float, passenger_priority: List[int], driver_priority: List[int], match_lb: int, cost: float, add_cost_const: bool, add_lb_const: bool, theta: float=1e-6) -> Tuple[pd.DataFrame, int, int, float]:\n",
        "    \"\"\" Computes the constrained maximum weight matching between drivers and passengers using a Mixed-Integer Linear Programming formulation.\n",
        "\n",
        "    Args:\n",
        "      distance_matrix (np.ndarray: Distance matrix of shape [num_cars, num_passengers] representing distances between each driver and passenger.\n",
        "      distance_threshold (float): Maximum feasible distance for an assignment. Any distance above this threshold is considered infeasible.\n",
        "      passenger_priority (List[int]): List indicating priority status of each passenger. Priority value `2` is considered \"priority\". Priority value `1` is considered non-\"priority\".\n",
        "      driver_priority (List[int]): List indicating priority status of each driver. Priority value `2` is considered \"priority\". Priority value `1` is considered non-\"priority\".\n",
        "      match_lb (int): Minimum number of required assignments.\n",
        "      cost (float): Max. feasible cost.\n",
        "      add_cost_const (bool): Whether to enforce the total cost constraint.\n",
        "      add_lb_const (bool): Whether to enforce the lower bound on total assignments.\n",
        "      theta (float): Relaxation parameter for the cost constraint.\n",
        "    \"\"\"\n",
        "    if len(distance_matrix) == 0:\n",
        "      raise ValueError(\"No participants!\")\n",
        "\n",
        "    num_drivers, num_passengers = distance_matrix.shape\n",
        "\n",
        "    if num_drivers != len(driver_priority):\n",
        "      raise ValueError(\"Number of drivers and driver_priority list length do not match.\")\n",
        "    if num_passengers != len(passenger_priority):\n",
        "      raise ValueError(\"Number of passengers and passenger_priority list length do not match.\")\n",
        "\n",
        "    mat = np.array(distance_matrix, copy=True)\n",
        "\n",
        "    #define the problem\n",
        "    max_weight_problem = LpProblem(\"Maximize_Total_Weight\", LpMaximize)\n",
        "\n",
        "    #add decision variables for feasible assignments\n",
        "    x = {(i, j): LpVariable(f\"x_{i}_{j}\", cat='Binary') for i in range(num_drivers) for j in range(num_passengers) if mat[i][j] <= distance_threshold}\n",
        "\n",
        "    #define the objective funtion\n",
        "    max_weight_problem += lpSum((driver_priority[i] + passenger_priority[j]) * x[i, j] for (i, j) in x)\n",
        "\n",
        "    #define constraints\n",
        "    #each driver can be assigned to at most one passenger\n",
        "    for i in range(num_drivers):\n",
        "        max_weight_problem += lpSum(x[i, j] for j in range(num_passengers) if (i, j) in x) <= 1\n",
        "\n",
        "    #each passenger can get assigned to at most one driver\n",
        "    for j in range(num_passengers):\n",
        "        max_weight_problem += lpSum(x[i, j] for i in range(num_drivers) if (i, j) in x) <= 1\n",
        "\n",
        "    #cost constraint\n",
        "    if add_cost_const:\n",
        "      max_weight_problem += lpSum(mat[i][j] * x[(i, j)] for (i, j) in x) <= cost*(1+theta)\n",
        "\n",
        "    #lower bound on the total number of assignments\n",
        "    if add_lb_const:\n",
        "      max_weight_problem += lpSum(x[(i, j)] for (i, j) in x) >= match_lb\n",
        "\n",
        "    start = time.time()\n",
        "    #solve the LP problem\n",
        "    max_weight_problem.solve()\n",
        "    end = time.time()\n",
        "    objective_value = value(max_weight_problem.objective)\n",
        "\n",
        "    #extract the solution\n",
        "    matching = [(i, j) for (i, j) in x if value(x[i, j]) == 1]\n",
        "    car_ind =  [i for (i,j) in matching]\n",
        "    pass_ind =  [j for (i,j) in matching]\n",
        "    assignment_distances = [mat[i, j]  for (i, j) in matching]\n",
        "\n",
        "    assignment_df = pd.DataFrame({\"car_ind\": car_ind, \"pass_ind\": pass_ind, \"dist\": assignment_distances})\n",
        "\n",
        "    total_cost = assignment_df[\"dist\"].sum()\n",
        "    matched_cars = assignment_df[\"car_ind\"].nunique()\n",
        "    matched_pass = assignment_df[\"pass_ind\"].nunique()\n",
        "\n",
        "    if matched_cars != matched_pass:\n",
        "      raise Exception(\"Unmatched assignment: number of matched cars and passengers differ.\")\n",
        "\n",
        "    num_matched_priority_p = assignment_df[\"pass_ind\"].apply(lambda j: passenger_priority[j] != 1).sum()\n",
        "    num_matched_priority_d = assignment_df[\"car_ind\"].apply(lambda i: driver_priority[i] != 1).sum()\n",
        "\n",
        "    return len(assignment_df), int(num_matched_priority_p), int(num_matched_priority_d), float(total_cost), objective_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xib4BiqEoG5v"
      },
      "outputs": [],
      "source": [
        "def price_of_priority(distance_threshold:float, distance_matrix: np.ndarray, passenger_priority: List[int], driver_priority: List[int], theta_step: float = 0.1, add_lb_const: bool = True) -> pd.DataFrame:\n",
        "  \"\"\"\n",
        "  Compute the price of priority by comparing min-cost matching and constrained max-weight priority matching.\n",
        "\n",
        "  Args:\n",
        "    distance_threshold (float): Maximum feasible distance for assignments.\n",
        "    distance_matrix (np.ndarray): Driver-passenger distance matrix.\n",
        "    passenger_priority (List[int]): List of passenger priorities (2 = priority).\n",
        "    driver_priority (List[int]): List of driver priorities (2 = priority).\n",
        "    theta_step (float, optional): Step size for relaxing cost constraint. Default 0.01.\n",
        "    add_lb_const (bool, optional): Whether to enforce lower bound on assignments in priority matching. Default True.\n",
        "  \"\"\"\n",
        "\n",
        "  summary = []\n",
        "\n",
        "  num_priority_passengers = sum(p != 1 for p in passenger_priority)\n",
        "  num__passengers = len(passenger_priority)\n",
        "  num_priority_drivers = sum(d != 1 for d in driver_priority)\n",
        "  num_drivers = len(driver_priority)\n",
        "\n",
        "  #solve min cost matching\n",
        "  number_of_assignments_min_cost, num_matched_priority_passengers_min_cost, num_matched_priority_drivers_min_cost, total_cost_min, objective_value_min_cost = min_cost_matching(distance_matrix,\n",
        "                                                                                                                                         distance_threshold,\n",
        "                                                                                                                                         passenger_priority,\n",
        "                                                                                                                                         driver_priority)\n",
        "\n",
        "  summary.append({\"status\": \"min_cost\",\n",
        "                  \"cost\": total_cost_min,\n",
        "                  \"number_of_assignments\": number_of_assignments_min_cost,\n",
        "                  \"matched_priority_driver\": num_matched_priority_drivers_min_cost,\n",
        "                  \"matched_priority_passenger\": num_matched_priority_passengers_min_cost,\n",
        "                  \"passenger_priority_gain_over_min_cost\": 0,\n",
        "                  \"theta\": None,\n",
        "                  \"number_of_passengers\": num__passengers,\n",
        "                  \"number_of_priority_passengers\": num_priority_passengers,\n",
        "                  \"number_of_drivers\": num_drivers,\n",
        "                  \"number_of_priority_drivers\": num_priority_drivers,\n",
        "                  \"objective_value\": objective_value_min_cost\n",
        "                  })\n",
        "\n",
        "  #solve max weight matching to find priority matching\n",
        "  number_of_assignments_max_priority, passenger_priority_matching_number, driver_priority_matching_number, total_cost_max, objective_value_max_weight = constrained_max_weight_matching(distance_matrix=distance_matrix,\n",
        "                                                                                                                                           distance_threshold=distance_threshold,\n",
        "                                                                                                                                           passenger_priority=passenger_priority,\n",
        "                                                                                                                                           driver_priority=driver_priority,\n",
        "                                                                                                                                           match_lb=number_of_assignments_min_cost,\n",
        "                                                                                                                                           cost=total_cost_min,\n",
        "                                                                                                                                           add_cost_const=False,\n",
        "                                                                                                                                           add_lb_const=add_lb_const)\n",
        "  summary.append({\"status\": \"max_priority\",\n",
        "                  \"cost\": total_cost_max,\n",
        "                  \"number_of_assignments\": number_of_assignments_max_priority,\n",
        "                  \"matched_priority_driver\": driver_priority_matching_number,\n",
        "                  \"matched_priority_passenger\": passenger_priority_matching_number,\n",
        "                  \"passenger_priority_gain_over_min_cost\": passenger_priority_matching_number - num_matched_priority_passengers_min_cost,\n",
        "                  \"theta\": None,\n",
        "                  \"number_of_passengers\": num__passengers,\n",
        "                  \"number_of_priority_passengers\": num_priority_passengers,\n",
        "                  \"number_of_drivers\": num_drivers,\n",
        "                  \"number_of_priority_drivers\": num_priority_drivers,\n",
        "                  \"objective_value\": objective_value_max_weight\n",
        "                  })\n",
        "\n",
        "  num_matched_priority_passengers = num_matched_priority_passengers_min_cost\n",
        "  num_matched_priority_drivers = num_matched_priority_drivers_min_cost\n",
        "  number_of_assignments = number_of_assignments_min_cost\n",
        "  total_cost = total_cost_min\n",
        "  objective_value = objective_value_min_cost\n",
        "  theta = 0\n",
        "\n",
        "  if (num_matched_priority_passengers_min_cost != passenger_priority_matching_number) | (num_matched_priority_drivers_min_cost != driver_priority_matching_number):\n",
        "    theta = -theta_step\n",
        "    while (num_matched_priority_passengers != passenger_priority_matching_number) | (num_matched_priority_drivers != driver_priority_matching_number):\n",
        "      theta += theta_step\n",
        "      number_of_assignments, num_matched_priority_passengers, num_matched_priority_drivers, total_cost, objective_value = constrained_max_weight_matching(distance_matrix=distance_matrix,\n",
        "                                                                                                                                distance_threshold=distance_threshold,\n",
        "                                                                                                                                passenger_priority=passenger_priority,\n",
        "                                                                                                                                driver_priority=driver_priority,\n",
        "                                                                                                                                match_lb=number_of_assignments_min_cost,\n",
        "                                                                                                                                cost=total_cost_min,\n",
        "                                                                                                                                add_cost_const=True,\n",
        "                                                                                                                                add_lb_const=add_lb_const,\n",
        "                                                                                                                                theta=theta)\n",
        "\n",
        "      summary.append({\"status\": f\"{theta:.0%}\",\n",
        "                      \"cost\": total_cost,\n",
        "                      \"number_of_assignments\": number_of_assignments,\n",
        "                      \"matched_priority_driver\": num_matched_priority_drivers,\n",
        "                      \"matched_priority_passenger\": num_matched_priority_passengers,\n",
        "                      \"passenger_priority_gain_over_min_cost\": num_matched_priority_passengers - num_matched_priority_passengers_min_cost,\n",
        "                      \"theta\": theta,\n",
        "                      \"number_of_passengers\": num__passengers,\n",
        "                      \"number_of_priority_passengers\": num_priority_passengers,\n",
        "                      \"number_of_drivers\": num_drivers,\n",
        "                      \"number_of_priority_drivers\": num_priority_drivers,\n",
        "                      \"objective_value\": objective_value\n",
        "                      })\n",
        "\n",
        "  else:\n",
        "    theta = 0\n",
        "    summary.append({\"status\": f\"{theta:.0%}\",\n",
        "                    \"cost\": total_cost,\n",
        "                    \"number_of_assignments\": number_of_assignments,\n",
        "                    \"matched_priority_driver\": num_matched_priority_drivers,\n",
        "                    \"matched_priority_passenger\": num_matched_priority_passengers,\n",
        "                    \"passenger_priority_gain_over_min_cost\": num_matched_priority_passengers - num_matched_priority_passengers_min_cost,\n",
        "                    \"theta\": theta,\n",
        "                    \"number_of_passengers\": num__passengers,\n",
        "                    \"number_of_priority_passengers\": num_priority_passengers,\n",
        "                    \"number_of_drivers\": num_drivers,\n",
        "                    \"number_of_priority_drivers\": num_priority_drivers,\n",
        "                    \"objective_value\": objective_value\n",
        "                    })\n",
        "\n",
        "  summary.append({\"status\": \"max_priority_min_cost\",\n",
        "                  \"cost\": total_cost,\n",
        "                  \"number_of_assignments\": number_of_assignments,\n",
        "                  \"matched_priority_driver\": num_matched_priority_drivers,\n",
        "                  \"matched_priority_passenger\": num_matched_priority_passengers,\n",
        "                  \"passenger_priority_gain_over_min_cost\": num_matched_priority_passengers - num_matched_priority_passengers_min_cost,\n",
        "                  \"theta\": theta,\n",
        "                  \"number_of_passengers\": num__passengers,\n",
        "                  \"number_of_priority_passengers\": num_priority_passengers,\n",
        "                  \"number_of_drivers\": num_drivers,\n",
        "                  \"number_of_priority_drivers\": num_priority_drivers,\n",
        "                  \"objective_value\": objective_value\n",
        "                  })\n",
        "  summary_df = pd.DataFrame(summary)\n",
        "\n",
        "  summary_df[\"perc_deviation_from_min_cost\"] = summary_df[\"cost\"].apply(lambda x: f\"{round((x - total_cost_min) / total_cost_min, 1):.0%}\")\n",
        "  summary_df[\"passenger_priority_matching_number\"] = passenger_priority_matching_number\n",
        "  summary_df[\"driver_priority_matching_number\"] = driver_priority_matching_number\n",
        "  summary_df[\"matched_passenger_ratio\"] = round(summary_df[\"number_of_assignments\"] / summary_df[\"number_of_passengers\"], 2)\n",
        "  summary_df[\"matched_priority_passenger_ratio\"] = round(summary_df[\"matched_priority_passenger\"] / summary_df[\"number_of_priority_passengers\"], 2)\n",
        "\n",
        "  return summary_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vlOZjvMCgQg"
      },
      "outputs": [],
      "source": [
        "def run_experiment(source_folder: str, outdir: str, distance_threshold: float = 5000, theta_step: float = 0.1, add_lb_const: bool = True) -> None:\n",
        "  \"\"\"\n",
        "  Run simulation experiments across multiple parameter sets and seeds, generates aggregated results and saves them to CSV.\n",
        "\n",
        "  ARgs:\n",
        "  source_folder (str): Directory containing experiment input CSV files. Files must follow the naming pattern \"df1_{i:03d}_{j:03d}.csv\" and \"df2_{i:03d}_{j:03d}.csv\".\n",
        "  outdir (str): Directory where output CSV will be written.\n",
        "  distance_threshold (float): Maximum feasible distance for assignments (default: 5000 meters).\n",
        "  theta_step (float): Step size for theta parameter in price_of_priority (default: 0.1).\n",
        "  add_lb_const (bool): Whether to add a lower-bound constraint in price_of_priority (default: True).\n",
        "  \"\"\"\n",
        "\n",
        "  results_list = []\n",
        "\n",
        "  for i in [1,2,3]:\n",
        "      for j in range(1,101):\n",
        "        file_name1 = \"df1_\"+str(i).rjust(3, '0')+\"_\"+str(j).rjust(3, '0')+\".csv\"\n",
        "        file_name2 = \"df2_\"+str(i).rjust(3, '0')+\"_\"+str(j).rjust(3, '0')+\".csv\"\n",
        "\n",
        "        path1 = os.path.join(source_folder, file_name1)\n",
        "        path2 = os.path.join(source_folder, file_name2)\n",
        "\n",
        "        if not os.path.exists(path1) or not os.path.exists(path2):\n",
        "          raise FileNotFoundError(f\"Missing input files: {path1}, {path2}\")\n",
        "\n",
        "        df1 = pd.read_csv(path1)\n",
        "        df2 = pd.read_csv(path2)\n",
        "\n",
        "        df1['loc'] = df1['loc'].apply(ast.literal_eval)\n",
        "        df2['loc'] = df2['loc'].apply(ast.literal_eval)\n",
        "\n",
        "        distance_matrix = distance.cdist(list(df2[\"loc\"]),  list(df1[\"loc\"]), 'cityblock')\n",
        "\n",
        "        for priority_level in [0.05, 0.1, 0.2, 0.3]:\n",
        "          priority_col = f\"priority_{priority_level}\"\n",
        "          if priority_col not in df1.columns:\n",
        "            raise KeyError(f\"Missing priority column: {priority_col}\")\n",
        "\n",
        "          passenger_priority_list = [1 if x == 0 else 100 for x in df1[priority_col]]\n",
        "          driver_priority_list = [1] * len(df2)\n",
        "\n",
        "          res_df = price_of_priority(\n",
        "                    distance_threshold=distance_threshold,\n",
        "                    distance_matrix=distance_matrix,\n",
        "                    passenger_priority=passenger_priority_list,\n",
        "                    driver_priority=driver_priority_list,\n",
        "                    theta_step=theta_step,\n",
        "                    add_lb_const=add_lb_const\n",
        "                )\n",
        "\n",
        "          res_df[\"priority_level\"] =  priority_level\n",
        "          res_df[\"seed\"] = j\n",
        "          res_df[\"params_set\"] = i\n",
        "\n",
        "          results_list.append(res_df)\n",
        "\n",
        "  results_df = pd.concat(results_list, ignore_index=True)\n",
        "\n",
        "  today=datetime.datetime.now().strftime('%Y%m%d')\n",
        "  os.makedirs(outdir, exist_ok=True)\n",
        "\n",
        "  if add_lb_const:\n",
        "    out_path = os.path.join(outdir, f'results_with_lb_constraint_100_{today}.csv')\n",
        "  else:\n",
        "    out_path = os.path.join(outdir, f'results_without_lb_constraint_100_{today}.csv')\n",
        "\n",
        "  results_df.to_csv(out_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "source_folder = \"\"\n",
        "outdir = \"\""
      ],
      "metadata": {
        "id": "3o4yYkejizEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkXC0Db6PRmU"
      },
      "source": [
        "## **Run with the lower bound constraint**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "GiWou6b1vqe5"
      },
      "outputs": [],
      "source": [
        "run_experiment(source_folder, outdir, add_lb_const=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQu_aFGzPaCI"
      },
      "source": [
        "## **Run without the lower bound constraint**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOB3pi04lj_p"
      },
      "outputs": [],
      "source": [
        "run_experiment(source_folder, outdir, add_lb_const=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzIPCPGW0UWS"
      },
      "source": [
        "## **Analyze Results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLXPRnKK0El9"
      },
      "outputs": [],
      "source": [
        "def get_aggregated_results(df: pd.DataFrame) -> pd.DataFrame:\n",
        "  \"\"\"\n",
        "  Aggregate experimental results by theta, parameter set, and priority level.\n",
        "\n",
        "  Args:\n",
        "  df (pd.DataFrame): Input dataframe containing columns: [\"theta\", \"params_set\", \"priority_level\", \"seed\", \"matched_priority_passenger\", \"matched_passenger_ratio\", \"is_priority_matching\"]\n",
        "  \"\"\"\n",
        "  aggregated_dfs = []\n",
        "\n",
        "  for priority_level  in df[\"priority_level\"].unique():\n",
        "    for params_set  in df[\"params_set\"].unique():\n",
        "\n",
        "      sub_df = df[(df[\"params_set\"] == params_set) & (df[\"priority_level\"] == priority_level)].copy()\n",
        "      max_length = int(sub_df.theta.max() * 10) + 1\n",
        "      grouped = sub_df.groupby('seed')\n",
        "\n",
        "      df_analyze = pd.DataFrame()\n",
        "\n",
        "      for seed, group in grouped:\n",
        "        #Pad rows to match max_length\n",
        "        rows_to_add = max_length - len(group)\n",
        "\n",
        "        if rows_to_add > 0:\n",
        "          last_row = group.iloc[-1].copy()\n",
        "          padding = pd.DataFrame([last_row] * rows_to_add)\n",
        "          group = pd.concat([group, padding], ignore_index=True)\n",
        "\n",
        "        group[\"status\"] = [f\"{int(x/10*100)}%\"  for x in range(max_length)]\n",
        "        group[\"theta\"] = [round(x/10,1) for x in range(max_length)]\n",
        "        df_analyze = pd.concat([df_analyze, group], ignore_index=True)\n",
        "\n",
        "      agg_df = (df_analyze[['theta', 'params_set', 'priority_level', 'matched_priority_passenger', 'matched_priority_passenger_ratio', 'matched_passenger_ratio', 'is_priority_matching']]\n",
        "               .groupby(['theta', 'params_set', 'priority_level'])\n",
        "               .agg(avg_matched_priority_passenger=('matched_priority_passenger', 'mean'),\n",
        "                    avg_ratio_of_matched_priority_passengers=('matched_priority_passenger_ratio', 'mean'),\n",
        "                    number_of_priority_matchings_obtained=('is_priority_matching', 'sum'),\n",
        "                    avg_ratio_of_matched_passengers=('matched_passenger_ratio', 'mean'),\n",
        "                    ).reset_index()\n",
        "               )\n",
        "\n",
        "      agg_df = agg_df.sort_values(['theta'])\n",
        "      agg_df['priority_matching_const_ratio'] = agg_df['number_of_priority_matchings_obtained']/100\n",
        "\n",
        "      aggregated_dfs.append(agg_df)\n",
        "\n",
        "  return aggregated_dfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TQD6elf2Q72"
      },
      "outputs": [],
      "source": [
        "def display_results(dfs: List[pd.DataFrame], palette: str = \"viridis\") -> None:\n",
        "  \"\"\"\n",
        "  Display line and scatter plots of matched priority agents over theta values.\n",
        "  Args:\n",
        "\n",
        "  dfs (List[pd.DataFrame]): List of aggregated DataFrames.\n",
        "  palette (str): Color palette for scatterplot. Default is 'viridis'.\n",
        "  \"\"\"\n",
        "  min_hue = 0\n",
        "  max_hue = 1\n",
        "  palette = palette\n",
        "\n",
        "  for i, df in enumerate(dfs, start=1):\n",
        "      fig, ax = plt.subplots(figsize=(10, 10))\n",
        "\n",
        "      sns.lineplot(data=df,\n",
        "                  x='theta',\n",
        "                  y='avg_ratio_of_matched_priority_passengers',\n",
        "                  color='gray',\n",
        "                  alpha=0.5,\n",
        "                  ax=ax,\n",
        "                  zorder=1,\n",
        "                  )\n",
        "      sns.scatterplot(\n",
        "          data=df,\n",
        "          x='theta',\n",
        "          y='avg_ratio_of_matched_priority_passengers',\n",
        "          hue='priority_matching_const_ratio',\n",
        "          palette=palette,\n",
        "          hue_norm=(min_hue, max_hue),\n",
        "          ax = ax,\n",
        "          zorder=2,\n",
        "          s=200,\n",
        "          legend=False,\n",
        "      )\n",
        "\n",
        "      norm = plt.Normalize(vmin=min_hue, vmax=max_hue)\n",
        "      sm = plt.cm.ScalarMappable(cmap=palette, norm=norm)\n",
        "      sm.set_array([])\n",
        "      #fig.colorbar(sm, ax=ax, label='Priority Matching Formation Ratio')\n",
        "\n",
        "      plt.xlabel(r'Cost Constraint Relaxation Ratio $\\theta$')\n",
        "      plt.ylabel('Mean of Matched Priority Agents')\n",
        "      ax.set_title(f'Parameter Setting {df[\"params_set\"].unique()}, Priority Level {df[\"priority_level\"].unique()}')\n",
        "\n",
        "      plt.grid(True, alpha=0.4)\n",
        "      plt.xticks(rotation=45)\n",
        "      ax.xaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
        "      sns.despine()\n",
        "\n",
        "      plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysJ_MpQ23aKS"
      },
      "outputs": [],
      "source": [
        "def display_results_grid(dfs: List[pd.DataFrame], palette: str = \"viridis\") -> None:\n",
        "  \"\"\"\n",
        "  Display aggregated results on a grid of subplots for multiple parameter settings and priority levels.\n",
        "\n",
        "  Args:\n",
        "        dfs (List[pd.DataFrame]): List of aggregated DataFrames.\n",
        "        palette (str): Colormap for scatterplot points.\n",
        "  \"\"\"\n",
        "\n",
        "  plt.rcParams.update({\n",
        "    \"font.size\": 20,\n",
        "    \"axes.titlesize\": 24,\n",
        "    \"axes.labelsize\": 20,\n",
        "    \"xtick.labelsize\": 18,\n",
        "    \"ytick.labelsize\": 18,\n",
        "    \"legend.fontsize\": 18\n",
        "  })\n",
        "\n",
        "  min_hue = 0\n",
        "  max_hue = 1\n",
        "  palette = palette\n",
        "  norm = plt.Normalize(vmin=min_hue, vmax=max_hue)\n",
        "\n",
        "  all_params_sets = sorted({df[\"params_set\"].iloc[0] for df in dfs})\n",
        "  all_priority_levels = sorted({df[\"priority_level\"].iloc[0] for df in dfs})\n",
        "\n",
        "  fig, axes = plt.subplots(len(all_params_sets), len(all_priority_levels), figsize=(32,24))\n",
        "  plt.subplots_adjust(left=0.05, right=1, top=0.95, bottom=0.08, hspace=0.2, wspace=0.1)\n",
        "\n",
        "  for df in dfs:\n",
        "      c_idx = all_priority_levels.index(df[\"priority_level\"].iloc[0])\n",
        "      r_idx = all_params_sets.index(df[\"params_set\"].iloc[0])\n",
        "      ax = axes[r_idx, c_idx]\n",
        "      sns.lineplot(data=df,\n",
        "                  x='theta',\n",
        "                  y='avg_ratio_of_matched_priority_passengers',\n",
        "                  color='gray',\n",
        "                  alpha=0.5,\n",
        "                  ax=ax,\n",
        "                  zorder=1,\n",
        "                  )\n",
        "      sns.scatterplot(\n",
        "          data=df,\n",
        "          x='theta',\n",
        "          y='avg_ratio_of_matched_priority_passengers',\n",
        "          hue='priority_matching_const_ratio',\n",
        "          palette=palette,\n",
        "          hue_norm=(min_hue, max_hue),\n",
        "          ax = ax,\n",
        "          zorder=2,\n",
        "          s=200,\n",
        "          legend=False,\n",
        "      )\n",
        "\n",
        "      ax.xaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
        "      ax.grid(True, alpha=0.4)\n",
        "      sns.despine()\n",
        "\n",
        "      dataset_ratio = {1: '12/50', 2: '25/50', 3: '37/50'}.get(df['params_set'].iloc[0], '')\n",
        "      ax.set_title(f\"Priority {df['priority_level'].iloc[0]} - {dataset_ratio}\")\n",
        "      ax.set_xlabel(\"\")\n",
        "      ax.set_ylabel(\"\")\n",
        "\n",
        "  sm = plt.cm.ScalarMappable(cmap=palette, norm=norm)\n",
        "  sm.set_array([])\n",
        "  cax = fig.add_axes([1.05, 0.15, 0.05, 0.7])\n",
        "  fig.colorbar(sm, cax=cax, orientation='vertical').set_label(label='Priority Matching Formation Ratio', size=24)\n",
        "\n",
        "  fig.supxlabel(r'Cost Constraint Relaxation Ratio $\\theta$', fontsize=24)\n",
        "  fig.supylabel('Mean of Matched Priority Agents', fontsize=24)\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzPgHOanOaMi"
      },
      "source": [
        "### **Results with the lower bound constraint**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLoZNiFqa4X0"
      },
      "outputs": [],
      "source": [
        "file_path = os.path.join(outdir, f'results_with_lb_constraint_100_20251018.csv')\n",
        "results_df_with_constraint = pd.read_csv(file_path, converters={\"loc\": ast.literal_eval})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGTRizYspY5i"
      },
      "outputs": [],
      "source": [
        "results_df_with_constraint.drop(results_df_with_constraint[results_df_with_constraint['status'] == 'max_priority_min_cost'].index, inplace=True)\n",
        "results_df_with_constraint.drop(results_df_with_constraint[results_df_with_constraint['status'] == 'min_cost'].index, inplace=True)\n",
        "results_df_with_constraint.drop(results_df_with_constraint[results_df_with_constraint['status'] == 'max_priority'].index, inplace=True)\n",
        "results_df_with_constraint.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEnYUA1OkJdZ"
      },
      "outputs": [],
      "source": [
        "results_df_with_constraint['is_priority_matching'] = results_df_with_constraint['matched_priority_passenger'] == results_df_with_constraint['passenger_priority_matching_number']\n",
        "aggregated_results_with_constraint = get_aggregated_results(results_df_with_constraint)\n",
        "aggregated_results_with_constraint_concat = pd.concat(aggregated_results_with_constraint, axis=0, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [1, 2, 3]:\n",
        "  df_temp = aggregated_results_with_constraint_concat[aggregated_results_with_constraint_concat['params_set'] == i]\n",
        "  #df_agg = df_temp.groupby(['params_set', 'priority_level', 'theta'])[['avg_ratio_of_matched_passengers', 'avg_ratio_of_matched_priority_passengers', 'number_of_priority_matchings_obtained']].mean()\n",
        "  display(df_temp.groupby(['params_set', 'priority_level', 'theta'])[['avg_ratio_of_matched_passengers', 'avg_ratio_of_matched_priority_passengers', 'number_of_priority_matchings_obtained']].mean())"
      ],
      "metadata": {
        "id": "Jg6t4pUkgdKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_results_grid(aggregated_results_with_constraint)"
      ],
      "metadata": {
        "id": "_M0zlvd9gq7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7ckOInWOraZ"
      },
      "source": [
        "### **Results without the lower bound constraint**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxAc-SOgzabB"
      },
      "outputs": [],
      "source": [
        "file_path = os.path.join(outdir, f'results_without_lb_constraint_100_20251018.csv')\n",
        "results_df_without_constraint = pd.read_csv(file_path, converters={\"loc\": ast.literal_eval})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBPJE8rMPCRQ"
      },
      "outputs": [],
      "source": [
        "results_df_without_constraint.drop(results_df_without_constraint[results_df_without_constraint['status'] == 'max_priority_min_cost'].index, inplace=True)\n",
        "results_df_without_constraint.drop(results_df_without_constraint[results_df_without_constraint['status'] == 'min_cost'].index, inplace=True)\n",
        "results_df_without_constraint.drop(results_df_without_constraint[results_df_without_constraint['status'] == 'max_priority'].index, inplace=True)\n",
        "results_df_without_constraint.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gz7boDLUPCRQ"
      },
      "outputs": [],
      "source": [
        "results_df_without_constraint['is_priority_matching'] = results_df_without_constraint['matched_priority_passenger'] == results_df_without_constraint['passenger_priority_matching_number']\n",
        "aggregated_results_without_constraint = get_aggregated_results(results_df_without_constraint)\n",
        "aggregated_results_without_constraint_concat = pd.concat(aggregated_results_without_constraint, axis=0, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [1, 2, 3]:\n",
        "  df_temp = aggregated_results_without_constraint_concat[aggregated_results_without_constraint_concat['params_set'] == i]\n",
        "  display(df_temp.groupby(['params_set', 'priority_level', 'theta'])[['avg_ratio_of_matched_passengers', 'avg_ratio_of_matched_priority_passengers', 'number_of_priority_matchings_obtained']].mean())"
      ],
      "metadata": {
        "id": "4ONZNZgPhP3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8ts_Ioe0Qao"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPVpxmShBA63"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}